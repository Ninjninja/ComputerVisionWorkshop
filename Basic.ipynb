{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,  time\n",
    "import ipywidgets as widget\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image as PIL_Image\n",
    "from io import BytesIO\n",
    "cv2.startWindowThread()\n",
    "def img_to_png(ima, cvt=None):\n",
    "    if cvt:\n",
    "        ima = cv2.cvtColor(ima, cvt)\n",
    "    im = PIL_Image.fromarray(ima)\n",
    "    bio = BytesIO()\n",
    "    im.save(bio, format='png')\n",
    "    return bio.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "sd = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "fr = cv2.face.createEigenFaceRecognizer()\n",
    "fd = dlib.get_frontal_face_detector()\n",
    "r = fd(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1920)\n",
    "cap.set(4,1080)\n",
    "while True:\n",
    "    ret, img0 = cap.read()\n",
    "    img = cv2.resize(img0, (640,360))\n",
    "    H, W = img.shape[:2]    \n",
    "    keycode = cv2.waitKey(1) & 0xff\n",
    "    if  keycode == ord('q'):\n",
    "        break\n",
    "    #imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "    #im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #cv2.drawContours(img, contours, -1, (0,255,0), 1)\n",
    "    \n",
    "    #img = edges = cv2.Canny(img,100,200)\n",
    "    #img[:,:,0] += edges*128\n",
    "    \"\"\" \n",
    "    mask = np.zeros(img.shape[:2],np.uint8)\n",
    "    bgdModel = np.zeros((1,65),np.float64)\n",
    "    fgdModel = np.zeros((1,65),np.float64)\n",
    "    rect = (50,50,450,290)\n",
    "    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "    img = img*mask2[:,:,np.newaxis]\n",
    "    \"\"\"\n",
    "    rl = fd(img)\n",
    "    for r in rl:\n",
    "        shape = sd(img, r)\n",
    "        poly = np.int32([(x.x, x.y) for x in shape.parts()])*2\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[:17]]) , 0, (0,255,255))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[17:22]]) , 0, (255,0,255))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[22:27]]) , 0, (255,0,255))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[27:31]]) , 0, (0,255,0))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[30:36]]) , 1, (0,255,0))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[36:42]]) , 1, (255,255,255))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[42:48]]) , 1, (255,255,255))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[48:60]]) , 1, (255,255,0))\n",
    "        img0 = cv2.polylines(img0, np.int32([poly[60:68]]) , 1, (255,255,0))\n",
    "        #img = cv2.rectangle(img, (r.left(),r.top()), (r.right(),r.bottom()),  (255,255,0))\n",
    "    \n",
    "    img0 = cv2.flip(img0, 1)\n",
    "    cv2.imshow('frame', img0)\n",
    "\n",
    "    #time.sleep(0.3)\n",
    "cv2.destroyWindow('frame')\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seg1():   \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    markers = cv2.watershed(img,markers)\n",
    "    img[markers == -1] = [255,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    cv2.imshow('im2', img2)\n",
    "    keycode = cv2.waitKey(1) & 0xff\n",
    "    if  keycode == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "point(278, 157)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape.part(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(278, 132),\n",
       " (278, 157),\n",
       " (278, 181),\n",
       " (281, 205),\n",
       " (290, 226),\n",
       " (304, 244),\n",
       " (323, 258),\n",
       " (345, 267),\n",
       " (368, 270),\n",
       " (390, 267),\n",
       " (406, 257),\n",
       " (420, 243),\n",
       " (431, 226),\n",
       " (438, 208),\n",
       " (443, 187),\n",
       " (445, 168),\n",
       " (447, 150),\n",
       " (309, 108),\n",
       " (321, 95),\n",
       " (338, 90),\n",
       " (355, 91),\n",
       " (371, 98),\n",
       " (392, 101),\n",
       " (407, 99),\n",
       " (422, 101),\n",
       " (434, 109),\n",
       " (440, 122),\n",
       " (381, 119),\n",
       " (381, 131),\n",
       " (382, 143),\n",
       " (383, 156),\n",
       " (360, 174),\n",
       " (370, 176),\n",
       " (379, 179),\n",
       " (387, 178),\n",
       " (394, 176),\n",
       " (326, 124),\n",
       " (335, 121),\n",
       " (345, 121),\n",
       " (353, 125),\n",
       " (345, 126),\n",
       " (335, 126),\n",
       " (398, 130),\n",
       " (408, 128),\n",
       " (417, 130),\n",
       " (424, 136),\n",
       " (416, 135),\n",
       " (407, 133),\n",
       " (342, 210),\n",
       " (357, 202),\n",
       " (369, 197),\n",
       " (377, 200),\n",
       " (384, 199),\n",
       " (393, 204),\n",
       " (400, 214),\n",
       " (391, 220),\n",
       " (382, 223),\n",
       " (373, 223),\n",
       " (366, 222),\n",
       " (354, 219),\n",
       " (347, 210),\n",
       " (369, 206),\n",
       " (376, 207),\n",
       " (384, 207),\n",
       " (395, 213),\n",
       " (383, 212),\n",
       " (375, 213),\n",
       " (367, 212)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
